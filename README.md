# HW4_Q4
This script simulates a data poisoning attack on a sentiment analysis classifier. It starts by training a logistic regression classifier on a small movie review dataset. The data poisoning step flips the sentiment labels of reviews mentioning "UC Berkeley" (e.g., changing positive reviews to negative ones and vice versa). After poisoning, the classifier is retrained on the modified data. The script then compares the classifier's performance by calculating accuracy and displaying confusion matrices before and after the poisoning attack. This shows how the model's accuracy and error rates degrade due to the intentional manipulation of training data.
